/usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
loaded pretrained LPIPS loss from taming/modules/autoencoder/lpips/vgg.pth
VQLPIPSWithDiscriminator running with hinge loss.
Traceback (most recent call last):
  File "main.py", line 354, in <module>
    main()
  File "main.py", line 348, in main
    model = instantiate_from_config(config.model)
  File "main.py", line 121, in instantiate_from_config
    return get_obj_from_str(config["target"])(**config.get("params", dict()))
  File "/data/joseph/Data_generation/diffusers-main/VQVAE/taming/models/vqgan.py", line 25, in __init__
    self.vqvae = VQSub(**ddconfig)
  File "/usr/local/lib/python3.8/dist-packages/diffusers/configuration_utils.py", line 611, in inner_init
    init(self, *args, **init_kwargs)
  File "/data/joseph/Data_generation/diffusers-main/VQVAE/taming/models/vqvae.py", line 49, in __init__
    self.decoder = Decoder(
  File "/data/joseph/Data_generation/diffusers-main/VQVAE/taming/models/hf_enc_dec.py", line 177, in __init__
    up_block = up_blk_getter(
  File "/data/joseph/Data_generation/diffusers-main/VQVAE/taming/models/unet_2d_blocks.py", line 354, in get_up_block
    return SDMUpDecoderBlock2D(
  File "/data/joseph/Data_generation/diffusers-main/VQVAE/taming/models/unet_2d_blocks.py", line 2357, in __init__
    SDMResnetBlock2D(
  File "/data/joseph/Data_generation/diffusers-main/VQVAE/taming/models/unet_2d_blocks.py", line 3375, in __init__
    super().__init__(in_channels=in_channels, out_channels=out_channels, *args, **kwargs)
  File "/usr/local/lib/python3.8/dist-packages/diffusers/models/resnet.py", line 514, in __init__
    self.conv2 = torch.nn.Conv2d(out_channels, conv_2d_out_channels, kernel_size=3, stride=1, padding=1)
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py", line 450, in __init__
    super(Conv2d, self).__init__(
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py", line 144, in __init__
    self.reset_parameters()
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py", line 150, in reset_parameters
    init.kaiming_uniform_(self.weight, a=math.sqrt(5))
  File "/usr/local/lib/python3.8/dist-packages/torch/nn/init.py", line 412, in kaiming_uniform_
    return tensor.uniform_(-bound, bound)
KeyboardInterrupt